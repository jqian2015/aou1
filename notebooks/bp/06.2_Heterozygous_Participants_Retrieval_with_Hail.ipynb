{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes a list of variants of interest and retrieves the list of participants who are heterozygous for each specific variant using Hail.\n",
    "\n",
    "Inputs: \n",
    "- **mt_path:** Path to the input file containing genotype data. In this example, we use the All of Us ACAf smaller callset split Hail MatrixTable.\n",
    "\n",
    "\n",
    "- **bed_path:** Path to the input file containing information about variants of interest. This file should include at least the locus and allele information for the variants and is expected to have a header. Locus is enough if you are not expecting exact match.\n",
    "\n",
    "We recommend saving you bed file as a hail table to speedup the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "    \n",
    "<li> Main node: 4CPUs, 15GB RAM, 100 GB Disk</li>\n",
    "\n",
    "<li> Workers (2/0): 4CPUs, 15GB RAM, 150GB Disk</li>\n",
    "\n",
    "<li> Time and Cost: \\$0.73/h, ~5min, \\$0.048</li>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hail as hl\n",
    "hl.default_reference(\"GRCh38\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "bucket = os.getenv(\"WORKSPACE_BUCKET\")\n",
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start = datetime.now()\n",
    "start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **mt_path:** Path to the input file containing genotype data. In this example, we use the All of Us ACAf smaller callset split Hail MatrixTable.\n",
    "\n",
    "\n",
    "- **bed_path:** Path to the input file containing information about variants of interest. This file should include at least the locus and allele information for the variants and is expected to have a header. Locus is enough if you are not expecting exact match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to inputs\n",
    "mt_path = \"gs://fc-aou-datasets-controlled/v8/wgs/short_read/snpindel/acaf_threshold/splitMT/hail.mt\"\n",
    "bed_path = \"gs://fc-secure-ff68a895-e88d-426e-9ae4-b3802c51b53b/notebooks/data/random_78_sites_GRCh38.ht\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load bed fiel into Hail\n",
    "bed = hl.read_table(bed_path)\n",
    "bed = bed.key_by(\"locus\", \"alleles\")\n",
    "bed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load matrixtable into Hail\n",
    "mt = hl.read_matrix_table(mt_path)\n",
    "mt.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We filter for African ancestry to avoid encountering resource issues while loading the output file. It takes the same time to work on all participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################remove in real analysis\n",
    "ancestry_pred_path = \"gs://fc-aou-datasets-controlled/v8/wgs/short_read/snpindel/aux/ancestry/ancestry_preds.tsv\"\n",
    "def filter_by_ancestry(mt, ancestry_pred_path, ancestry_filter=\"eur\"):\n",
    "    \"\"\"\n",
    "    Imports ancestry prediction data and filters a Hail MatrixTable by a specified ancestry.\n",
    "\n",
    "    Parameters:\n",
    "        mt (hl.MatrixTable): The input MatrixTable.\n",
    "        ancestry_pred_path (str): Path to the ancestry prediction file. This function use the all of us ancestry file, please make sure the format is the same as the all of us ancestry file if you are using other pop files.\n",
    "        ancestry_filter (str): The ancestry label to filter on (default is \"eur\").\n",
    "\n",
    "    Returns:\n",
    "        hl.MatrixTable: Filtered MatrixTable with ancestry annotations.\n",
    "    \"\"\"\n",
    "    ancestry_pred = hl.import_table(\n",
    "        ancestry_pred_path,\n",
    "        key=\"research_id\",\n",
    "        impute=True,\n",
    "        types={\"research_id\": hl.tstr, \"pca_features\": hl.tarray(hl.tfloat)}\n",
    "    )\n",
    "    \n",
    "    mt = mt.annotate_cols(ancestry_pred=ancestry_pred[mt.s])\n",
    "    mt = mt.filter_cols(mt.ancestry_pred.ancestry_pred_other == ancestry_filter)\n",
    "    \n",
    "    return mt\n",
    "\n",
    "# Usage\n",
    "#ancestry_pred_path = \"gs://fc-aou-preprod-datasets-controlled/v8/wgs/short_read/snpindel/aux/ancestry/echo_v4_r2.ancestry_preds.tsv\"\n",
    "#mt = filter_by_ancestry(mt, ancestry_pred_path, ancestry_filter=\"eur\")\n",
    "mt =  filter_by_ancestry(mt, ancestry_pred_path, ancestry_filter=\"afr\")\n",
    "mt.count()\n",
    "###################################remove in real analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the MatrixTable based on the intervals in the input BED file, and optionally, match the alleles as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to test interval or variants in bed file\n",
    "def filter_mt_by_intervals(mt, intervals):\n",
    "    \"\"\"\n",
    "    Filters a Hail MatrixTable to retain only specified genomic intervals.\n",
    "\n",
    "    Parameters:\n",
    "        mt (hl.MatrixTable): The input MatrixTable.\n",
    "        intervals (list): A list of genomic intervals in string format (e.g., 'chr5:66715539-66715540').\n",
    "                            examples: test_intervals = ['chr1:100M-200M', 'chr16:29.01M-29.02M']\n",
    "                                        test_intervals = ['chr21']\n",
    "\n",
    "    Returns:\n",
    "        hl.MatrixTable: Filtered MatrixTable.\n",
    "    \"\"\"\n",
    "    parsed_intervals = [hl.parse_locus_interval(x) for x in intervals]\n",
    "    return hl.filter_intervals(mt, parsed_intervals)\n",
    "\n",
    "# Usage\n",
    "\n",
    "#test_intervals = [\n",
    "#    'chr5:66715539-66715540', \n",
    " #   'chrX:9843055-9843056', \n",
    "  #  'chrX:51502424-51502425', \n",
    "   # 'chrX:67872303-67872304'\n",
    "#]\n",
    "\n",
    "#mt = filter_mt_by_intervals(mt, test_intervals)\n",
    "#mt.row.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create intervals and filter MT by intervals\n",
    "bed = bed.annotate(interval = bed.chr_grch38 + \":\" + hl.str(bed.pos_grch38) + \"-\" + hl.str(bed.pos_grch38 + 1))\n",
    "test_interval = bed.interval.collect()\n",
    "mt = filter_mt_by_intervals(mt, test_interval)\n",
    "mt.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#annotatemt by bed file in case there are other information of interest in the bed file \n",
    "mt = mt.annotate_rows(bed=bed[mt.row_key])\n",
    "mt.row.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exact match filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering by intervals will retain variants with alleles not present in the bed file. We can filter the rows to remove these extra variants, but keep in mind that row filtering can be slow and expensive. If this step doesn't affect your downstream analysis, you can skip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_filtered = mt.filter_rows(~hl.is_missing(mt.bed.chr_grch38))\n",
    "mt_filtered.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter genotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for heterozygous genotypes, others will be removed from the MT\n",
    "het_variants = mt_filtered.filter_entries(mt_filtered.GT.is_het())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract information needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert MatrixTable to a Table with heterozygous samples\n",
    "result_table = het_variants.entries()\n",
    "result_table = result_table.group_by(\n",
    "    locus = result_table.locus,\n",
    "    alleles = result_table.alleles\n",
    ").aggregate(\n",
    "    heterozygous_samples = hl.agg.collect_as_set(result_table.s)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check first several rows of the results\n",
    "result_table.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save results to bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We recommend load the saved file into Hail or other tools in a new notebook to avoid encountering any resource issues.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results as a tsv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table.export(f'{bucket}/data/heterozygous_participants.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved tsv into pandas\n",
    "import pandas as pd\n",
    "het_samples = f'{bucket}/data/heterozygous_participants.tsv'\n",
    "het_samples = pd.read_csv(het_samples, sep = \"\\t\")\n",
    "print(het_samples.head(5))\n",
    "\n",
    "# Convert string representation of lists to actual Python lists\n",
    "import ast\n",
    "het_samples[\"heterozygous_samples\"] = het_samples[\"heterozygous_samples\"].apply(ast.literal_eval)\n",
    "print(f\"{len(het_samples['heterozygous_samples'][0])} heterozygotes for the variant at locus {het_samples['locus'][0]} with alleles {het_samples['alleles'][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save results to buckst as a hail table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table.write(f'{bucket}/data/heterozygous_participants.ht')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved file into Hail\n",
    "het_samples_ht = f'{bucket}/data/heterozygous_participants.ht'\n",
    "het_samples_ht = hl.read_table(het_samples_ht)\n",
    "het_samples_ht.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = datetime.now()\n",
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil -m ls gs://fc-secure-ff68a895-e88d-426e-9ae4-b3802c51b53b/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
