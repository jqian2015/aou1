{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run a Hail notebook in the background\n",
    "\n",
    "On the *All of US* Workbench, users are logged out after 30 minutes of inactivity. For long running notebooks, such as Hail jobs, this means that users may not have all notebook cells populated even though the notebook continues to run to completion.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>If you wish to capture all notebook cell outputs</b>, use this notebook to run your long-running notebook.<p>But also note that your analysis <a href=\"https://support.terra.bio/hc/en-us/articles/360029761352-Preventing-runaway-costs-with-notebook-auto-pause-#h_de5698f5-3c82-4763-aaaf-ea7df6a1869c\">the cluster will autopause after 24 hours</a> <b>(right click)</b>. To prevent your cluster from shutting down if your background notebook execution takes longer than 24 hours, be sure to log in and start a notebook, any notebook, within the workspace where the background job is running to reset the autopause timer.</p>\n",
    "</div>\n",
    "\n",
    "How to use this notebook:\n",
    "1. Copy this notebook to the workspace that contains the long-running notebook you wish to run in the background.\n",
    "1. Edit the filename in `NOTEBOOK_TO_RUN` to be the name of the notebook in this workspace you wish to run.\n",
    "1. Use menu `Cell -> Run All` to tell the kernel to run this notebook to completion.\n",
    "1. Close this tab and do other work (note: when you close the tab, the outputs in *this* notebook will no longer be updated, and that is fine, because what we really want are the outputs in the notebook running in the background).\n",
    "1. When the background notebook execution is complete:\n",
    "    1. Your Cloud Analysis Environment will pause (if you have no other notebooks open and you did not change the [\"Automatically pause after idle\"](https://support.terra.bio/hc/en-us/articles/360029761352-Preventing-runaway-costs-with-notebook-auto-pause-#h_de5698f5-3c82-4763-aaaf-ea7df6a1869c) **(right click)** setting).\n",
    "    1. You will see a copy of your notebook in the notebooks tab with a date and timestamp suffix --> this is the output file.\n",
    "    1. You will also see the Hail log, if applicable, in `gs://<workspace bucket>/hail-logs/YYYYMMDD/hail*.log`\n",
    "\n",
    "If you check back, and you do not see the output notebook, the background job is still running.\n",
    "* To confirm this, first notice whether your Cloud Analysis Environment is still running (green dot next to thunder/cloud icon).\n",
    "* If it is still running, from the terminal:\n",
    "  * for Hail, run `yarn application -list` to see that a spark context is still processing data.\n",
    "  * for Python or R run `top` to see the processes using CPU and memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# suppress warning info\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # or '3' to suppress both INFO and WARNING logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import gzip\n",
    "import nbformat\n",
    "from nbconvert.preprocessors import CellExecutionError\n",
    "from nbconvert.preprocessors import ExecutePreprocessor\n",
    "# import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment these lines if you want to see your list of notebooks in the current working directory.\n",
    "#!pwd\n",
    "#!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Change the cell below</b> to:\n",
    "    <ol>\n",
    "        <li>specify the name of the notebook in this workspace that you wish to run in the background</li>\n",
    "        <li>set the kernel to <b>PYTHON</b> if you have a Hail or Python notebook. Set the kernel to <b>R</b> if you have an R notebook.</li>\n",
    "    </ol>\n",
    "There is no need to modify any of the other cells.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---[ Change this to be the name of the notebook in the current working directory that you wish to run. ]-----------\n",
    "NOTEBOOK_TO_RUN = 'your_notebook.ipynb'\n",
    "\n",
    "#---[ Change the following to 'PYTHON' if you have a Python notebook, or to 'R' if you have an R notebook.\n",
    "KERNEL = 'Python'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programmatically set output paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formulate a new filename for the output notebook so that it include a date and timestamp for when it was executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP_FILE_SUFFIX = time.strftime('_%Y%m%d_%H%M%S.ipynb')\n",
    "OUTPUT_NOTEBOOK = NOTEBOOK_TO_RUN.replace('.ipynb', TIMESTAMP_FILE_SUFFIX)\n",
    "\n",
    "print(f'Executed notebook will be written to filename \"{OUTPUT_NOTEBOOK}\" on the local disk and the workspace bucket.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATESTAMP = time.strftime('%Y%m%d')\n",
    "HAIL_LOG_DIR_FOR_PROVENANCE = os.path.join(os.getenv('WORKSPACE_BUCKET'), 'hail-logs', DATESTAMP)\n",
    "\n",
    "print(f'Hail logs, if any, will be copied to {HAIL_LOG_DIR_FOR_PROVENANCE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the notebook and capture provenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kernel(kernel):\n",
    "    return 'ir' if kernel.lower() == 'r' else 'python3'\n",
    "\n",
    "KERNEL_NAME = get_kernel(KERNEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "The next cell will use <kbd>nbconvert</kbd> to run the notebook in the background until it completes (or yields an error).\n",
    "    <ul>\n",
    "    <li>It will capture all notebook outputs as a separate notebook file and store it in the workspace bucket.</li>\n",
    "    <li>Hail logs, if any exist, will be copied from the execution directory on the local disk to the workspace bucket.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See also https://nbconvert.readthedocs.io/en/latest/execute_api.html\n",
    "with open(NOTEBOOK_TO_RUN) as f_in:\n",
    "    nb = nbformat.read(f_in, as_version=4)\n",
    "    ep = ExecutePreprocessor(timeout=-1, kernel_name=KERNEL_NAME)\n",
    "    try:\n",
    "        out = ep.preprocess(nb, {'metadata': {'path': ''}})\n",
    "    except CellExecutionError:\n",
    "        out = None\n",
    "        print(f'''Error executing the notebook \"{NOTEBOOK_TO_RUN}\".\n",
    "        See notebook \"{OUTPUT_NOTEBOOK}\" for the traceback.''')\n",
    "    finally:\n",
    "        with open(OUTPUT_NOTEBOOK, mode='w', encoding='utf-8') as f_out:\n",
    "            nbformat.write(nb, f_out)\n",
    "        # Save the executed notebook to the workspace bucket.\n",
    "        output_notebook_path = os.path.join(os.getenv('WORKSPACE_BUCKET'), 'notebooks', OUTPUT_NOTEBOOK)\n",
    "        tf.io.gfile.copy(src=OUTPUT_NOTEBOOK, dst=output_notebook_path)\n",
    "        print(f'Wrote executed notebook to {output_notebook_path}')\n",
    "\n",
    "# Save the hail logs, if any, to the workspace bucket.\n",
    "for hail_log in glob.glob('hail*.log'):\n",
    "    with open(hail_log, 'rb') as f_in:\n",
    "        compressed_hail_log = f'{hail_log}.gz'\n",
    "        with gzip.open(compressed_hail_log, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "    hail_log_path = os.path.join(HAIL_LOG_DIR_FOR_PROVENANCE, compressed_hail_log)\n",
    "    if not tf.io.gfile.exists(hail_log_path):\n",
    "        tf.io.gfile.copy(src=compressed_hail_log, dst=hail_log_path)\n",
    "        print(f'Wrote hail log to {hail_log_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
